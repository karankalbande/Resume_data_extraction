{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d38af4f-130a-41be-901d-5f50596c1d0e",
   "metadata": {},
   "source": [
    "# Resume Data Extraction Using Python and GenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e054c275-673b-423b-9a83-8e63073422bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Data:  {'PersonalData': {'Name': 'SHRIKRISHNA YADAV', 'Email': 'kissna.yadav7@gmail.com', 'Phone': '9137173338'}, 'ProfessionalSummary': '', 'WorkExperience': '', 'Education': '', 'Certifications': 'Not Found', 'Skills': ['Hive', 'Amchart', 'Flask Deep Learning', 'Django', 'Python', 'Hadoop SQL', 'JavaScript', 'Opencv', 'SQL', 'NoSQL Django', 'Sql', 'Computer Vision Azure', 'Pyspark', 'Ajax', 'Pan', 'Hadoop']}\n",
      "Extraction complete. Data saved to extracted_resume123.json.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import spacy\n",
    "import fitz  # PyMuPDF to extract text from PDF\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Load spaCy model (Make sure it's installed: python -m spacy download en_core_web_trf)\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "\n",
    "def load_text_from_pdf(file_path):\n",
    "    \"\"\"Extract text from a PDF file using PyMuPDF.\"\"\"\n",
    "    doc = fitz.open(file_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        text += page.get_text(\"text\")\n",
    "    return text\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean up the resume text by removing unwanted characters and normalizing spaces.\"\"\"\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespace and newlines\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)  # Remove non-ASCII characters\n",
    "    text = re.sub(r'\\s*\\n\\s*', '\\n', text)  # Normalize newline characters\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def extract_email(text):\n",
    "    \"\"\"Extract email addresses using a regular expression.\"\"\"\n",
    "    email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "    emails = re.findall(email_pattern, text)\n",
    "    return emails[0] if emails else \"Not Found\"\n",
    "\n",
    "def extract_phone(text):\n",
    "    \"\"\"Extract phone numbers using a refined regular expression.\"\"\"\n",
    "    phone_pattern = r'\\b(?:\\+?(\\d{1,3})[-.\\s]?)?(?:\\(?(\\d{3})\\)?[-.\\s]?)?(\\d{3})[-.\\s]?(\\d{4})\\b'\n",
    "    phones = re.findall(phone_pattern, text)\n",
    "    phone_numbers = [\"\".join(phone) for phone in phones]  # Join phone number parts\n",
    "    return phone_numbers[0] if phone_numbers else \"Not Found\"\n",
    "\n",
    "def fuzzy_find_section(text, possible_headings):\n",
    "    \"\"\"Finds the closest match to a given heading in the text using fuzzy matching.\"\"\"\n",
    "    lines = text.split('\\n')\n",
    "    for i, line in enumerate(lines):\n",
    "        for heading in possible_headings:\n",
    "            if fuzz.partial_ratio(heading.lower(), line.lower()) > 80:  # Fuzzy match with a threshold\n",
    "                return i  # Return the line index where the heading is found\n",
    "    return -1\n",
    "\n",
    "def extract_section(text, section_start_headings, next_section_headings=None):\n",
    "    \"\"\"Generic function to extract a section of text between a start and optional next sections using fuzzy matching.\"\"\"\n",
    "    start_idx = fuzzy_find_section(text, section_start_headings)\n",
    "    if start_idx == -1:\n",
    "        return \"\"\n",
    "\n",
    "    lines = text.split('\\n')\n",
    "    section_lines = []\n",
    "\n",
    "    if next_section_headings:\n",
    "        end_idx = fuzzy_find_section(\"\\n\".join(lines[start_idx + 1:]), next_section_headings)\n",
    "        if end_idx != -1:\n",
    "            end_idx += start_idx + 1  # Adjust relative index to absolute index\n",
    "        else:\n",
    "            end_idx = len(lines)  # If no end section found, take till the end of the text\n",
    "    else:\n",
    "        end_idx = len(lines)\n",
    "\n",
    "    for i in range(start_idx + 1, end_idx):\n",
    "        section_lines.append(lines[i].strip())\n",
    "\n",
    "    return \"\\n\".join(section_lines).strip()\n",
    "\n",
    "def preprocess_sections(section_text):\n",
    "    \"\"\"Further preprocess extracted sections to remove unwanted content (e.g., email, phone).\"\"\"\n",
    "    section_text = re.sub(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}', '', section_text)  # Remove emails\n",
    "    section_text = re.sub(r'\\b(?:\\+?(\\d{1,3})[-.\\s]?)?(?:\\(?(\\d{3})\\)?[-.\\s]?)?(\\d{3})[-.\\s]?(\\d{4})\\b', '', section_text)  # Remove phone numbers\n",
    "    section_text = section_text.strip()\n",
    "    return section_text\n",
    "\n",
    "def extract_resume_details(resume_text):\n",
    "    \"\"\"Uses spaCy NLP model to extract key details from the resume.\"\"\"\n",
    "    resume_text = clean_text(resume_text)  # Clean the resume text\n",
    "    doc = nlp(resume_text)\n",
    "\n",
    "    # Extract Name (PERSON entities)\n",
    "    names = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "\n",
    "    # Extract Emails and Phone Numbers\n",
    "    email = extract_email(resume_text)\n",
    "    phone = extract_phone(resume_text)\n",
    "\n",
    "    # Extract Professional Summary, Work Experience, and Education using fuzzy matching\n",
    "    professional_summary = extract_section(resume_text, [\"Professional Summary\", \"Summary\", \"Objective\"], next_section_headings=[\"Experience\", \"Work Experience\", \"Education\"])\n",
    "    work_experience = extract_section(resume_text, [\"Work Experience\", \"Experience\"], next_section_headings=[\"Education\", \"Certifications\", \"Skills\"])\n",
    "    education = extract_section(resume_text, [\"Education\", \"Academic Background\"], next_section_headings=[\"Certifications\", \"Skills\", \"Technical Skills\"])\n",
    "\n",
    "    # Preprocess the extracted sections to remove any unwanted content\n",
    "    professional_summary = preprocess_sections(professional_summary)\n",
    "    work_experience = preprocess_sections(work_experience)\n",
    "    education = preprocess_sections(education)\n",
    "\n",
    "    # Extract certifications (optional, handle cases where this section might not exist)\n",
    "    certifications = extract_section(resume_text, [\"Certifications\", \"Licenses\", \"Courses\"], next_section_headings=[\"Skills\", \"Technical Skills\"])\n",
    "\n",
    "    # Refine skills extraction by filtering out non-skill entities\n",
    "    skills = list(set([ent.text for ent in doc.ents if ent.label_ in [\"SKILL\", \"TECH\", \"PRODUCT\", \"LANGUAGE\"]]))\n",
    "    non_skills = [\"Technologies\", \"Pvt.\", \"Ltd.\", \"Institute\", \"University\", \"College\"]\n",
    "    skills = [skill for skill in skills if all(ns.lower() not in skill.lower() for ns in non_skills)]\n",
    "\n",
    "    # Build the extracted details into a structured format\n",
    "    extracted_details = {\n",
    "        \"PersonalData\": {\n",
    "            \"Name\": names[0] if names else \"Not Found\",\n",
    "            \"Email\": email,\n",
    "            \"Phone\": phone\n",
    "        },\n",
    "        \"ProfessionalSummary\": professional_summary,\n",
    "        \"WorkExperience\": work_experience,\n",
    "        \"Education\": education,\n",
    "        \"Certifications\": certifications if certifications else \"Not Found\",\n",
    "        \"Skills\": skills\n",
    "    }\n",
    "\n",
    "    return extracted_details\n",
    "\n",
    "def save_extracted_data(extracted_data, output_file):\n",
    "    \"\"\"Saves extracted data to a JSON file.\"\"\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(extracted_data, json_file, indent=4)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Input and Output file paths\n",
    "    resume_file = r\"D:\\Python\\Brainvire project\\Project all data\\karan\\karan\\Resume\\1695031952_shrikrishna yadav.pdf\"  # Replace with the actual path\n",
    "    output_file = \"extracted_resume123.json\"\n",
    "\n",
    "    # Load resume text from PDF\n",
    "    resume_text = load_text_from_pdf(resume_file)\n",
    "\n",
    "    # Extract information using spaCy\n",
    "    extracted_data = extract_resume_details(resume_text)\n",
    "    print(\"Extracted Data: \", extracted_data)\n",
    "\n",
    "    # Save the structured data to a JSON file\n",
    "    save_extracted_data(extracted_data, output_file)\n",
    "    print(f\"Extraction complete. Data saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437c4e96-46c5-4a40-8c0a-e94f7c7ac0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7913e8a-e775-44d9-818a-ffb11a5d9d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c187b361-7568-4dd8-8ec3-1b4f8f1d7cba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd905cfc-a0e8-4127-aae4-a0a59569076c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba300817-53c4-44ed-a52f-3b4ca825388a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53efb2b-49fc-4f60-80e2-c2980a984932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
